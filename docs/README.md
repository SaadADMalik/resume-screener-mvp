ğŸ“„Resume Screener

An end-to-end AI-powered application that ranks resumes against job descriptions using semantic similarity, keyword relevance, and quantified impact scoring. Built with a modular full-stack architecture (Streamlit + FastAPI) and fully containerized with Docker for reproducibility and deployment.

ğŸš€ Features

Upload multiple resumes (PDFs) and match them against a pasted or uploaded job description.

Hybrid ranking engine:

ğŸ”¹ Semantic similarity with SentenceTransformers
 (all-mpnet-base-v2).

ğŸ”¹ Keyword relevance using TF-IDF, SpaCy lemmatization, and fuzzy matching.

ğŸ”¹ Impact scoring that rewards quantified achievements (e.g., â€œreduced costs by 20%â€).

Explainable results with matched keywords and scoring breakdowns.

Batch processing: Rank multiple resumes in a single API request.

Streamlit UI for recruiters, FastAPI backend for compute-heavy tasks.

Dockerized deployment for consistent environments and cloud hosting.

ğŸ—ï¸ Architecture (only useful files)
ğŸ“‚ resume-screener
â”œâ”€â”€ frontend/          # Streamlit app for recruiter interaction
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ backend/           # FastAPI service
â”‚   â”œâ”€â”€ main.py        # API endpoints
â”‚   â”œâ”€â”€ ranking.py     # Scoring logic
â”‚   â”œâ”€â”€ nlp_utils.py   # Embeddings, TF-IDF, SpaCy preprocessing
â”œâ”€â”€ models/            # Pretrained SentenceTransformer + fine-tuning (optional)
â”œâ”€â”€ docker/            # Dockerfiles and compose setup
â””â”€â”€ README.md


Streamlit â†’ File upload, JD input, results visualization.

FastAPI + Uvicorn â†’ Stateless API with NLP pipelines.

Docker â†’ Containerized environment for reproducibility and scalability.

âš™ï¸ Tech Stack

Backend Framework: FastAPI (ASGI server with Uvicorn)

Frontend: Streamlit

NLP Models:

SentenceTransformers (all-mpnet-base-v2) for embeddings

SpaCy (en_core_web_sm) for tokenization + lemmatization

Scikit-learn (TF-IDF Vectorizer)

FuzzyWuzzy for approximate string matching

PDF Handling: PDFPlumber

Text Preprocessing: NLTK (stopwords, lemmatization)

Containerization: Docker

ğŸ”¬ Ranking Methodology

The ranking function balances three dimensions:

Semantic Similarity (60%) â†’ Contextual embedding similarity with SentenceTransformers.

Keyword Matching (30%) â†’ TF-IDF + SpaCy noun-chunk matching + fuzzy string overlap.

Impact Scoring (10%) â†’ Regex-based detection of action verbs + numerical achievements.

Example:
Resume A: â€œImproved sales by 25% using data-driven strategies.â€
Resume B: â€œResponsible for sales team tasks.â€
â†’ Resume A scores higher because of quantified, action-driven phrasing.

ğŸ“Š Explainability

Recruiters receive scoring breakdowns with:

Matched keywords per resume

Explanation of semantic similarity scores

Highlighted impact phrases

This turns the model into a transparent AI assistant, not a black box.

ğŸš¢ Deployment

Local:

docker-compose up --build


Cloud-ready: Designed for free-tier hosting (Render, Fly.io, Railway).

Stateless backend â†’ can scale horizontally with multiple Docker workers.

ğŸ§  Future Enhancements

 Fine-tune SentenceTransformers on resumeâ€“JD pairs (domain adaptation).

 Add retrieval evaluation metrics (MRR, nDCG, Precision@k).

 Integrate with ATS platforms via API.

 Support multilingual resumes and job descriptions.

 Deploy on Kubernetes for production-scale workloads.

ğŸ… Why This Project Matters

This project goes beyond simple keyword filtering by combining semantic NLP, explainability, and containerized deployment. Itâ€™s designed as a production-ready AI tool, not just a prototype â€” balancing algorithmic sophistication with real-world usability.
